---
title: "FOMO Killer"
description: "用 AI 终结信息焦虑。每日自动收集、筛选、总结 AI 领域最值得关注的内容。"
date: 2026-02-20
image: "/assets/images/project-ai-daily.jpg"
github: "https://github.com/RollingTheRock/ai-daily-digest"
demo: "https://github.com/RollingTheRock/ai-daily-digest"
tech: ["Python", "DeepSeek", "GitHub Actions", "Notion API", "SMTP"]
featured: true
---

## 病急乱投医

2026 年初，AI 领域的更新速度让人窒息。

每天早上打开电脑，Twitter 上有人发了新的 Agent 框架，GitHub Trending 又换了一批面孔，arXiv 多了二十篇论文，YouTube 上有人用新工具五分钟搭了一个 App。

我的第一反应不是兴奋，而是焦虑。

**我是不是又落后了？**

于是我开始每天花两三个小时"刷信息"。打开十几个标签页，从论文扫到博客，从博客跳到推特，从推特滑到视频。看完之后觉得自己好像什么都知道了，但坐下来写代码的时候，发现什么都没记住。

这就是 FOMO——Fear of Missing Out。你怕错过任何东西，结果错过了最重要的东西：**你自己的时间**。

---

## 那就造一个解药

既然问题是信息太多、太散、太杂，那解决思路也很简单：

**让机器去刷信息，我只看结论。**

FOMO Killer 做的事情：

1. **自动收集**：每天从论文、技术博客、GitHub 热门项目、Twitter、YouTube 等渠道抓取 AI 领域的最新内容
2. **AI 筛选摘要**：用 DeepSeek 对所有内容进行评估、筛选、总结，只保留真正值得关注的部分
3. **双路径送达**：
   - 一封精简的晨报邮件，发到你的邮箱
   - 同时自动写入 Notion 数据库，方便回顾和检索

每天一封。打开邮件，五分钟看完今天 AI 圈发生了什么。看完关掉。然后去写你自己的代码。

---

## 一个差点死掉的项目

说实话，第一版做出来之后，我自己都不用。

因为它太"勤快"了。每天推送几十条信息，论文、博客、项目一股脑塞过来。和我自己手动刷信息的唯一区别是——从十几个标签页变成了一封很长的邮件。

本质没变。信息还是太多了。

我一度觉得这是个伪需求。

后来我想明白了一件事：**问题不是收集得不够多，而是筛选得不够狠。**

我们每天开工之前，其实不需要知道那么多事情。我们需要知道的是：**今天有什么是真正重要的，值得我花时间去深入了解的。**

于是我重写了筛选逻辑。化繁为简。不是推送所有信息，而是只推送**值得你停下来看的东西**。

改完之后，我开始每天用了。

---

## 技术栈

架构很朴素，没有花哨的东西：

- **Python 爬虫**：从各个信息源抓取数据
- **DeepSeek**：对内容进行理解、评分、摘要
- **GitHub Actions**：每天定时触发，零运维
- **SMTP**：发送晨报邮件
- **Notion API**：将结构化数据写入 Notion 数据库

整套流程跑在 GitHub Actions 上，不需要服务器，不需要运维。Push 一下代码，它就开始每天自动工作了。

---

## 未来

FOMO Killer 现在只解决了一半的问题——**信息的输入**。

但信息进来之后呢？

你读了一篇论文摘要，觉得有意思，然后呢？三天之后你还记得它说了什么吗？

我想做的下一步是：

- **主动记笔记**：在 Notion 中直接对感兴趣的内容做标注和笔记
- **AI 增强笔记**：自动关联相关内容，补充上下文
- **定期检索总结**：AI 定期回顾你的笔记，发现你关注的趋势和模式
- **知识内化**：从"每天看了什么"变成"我真正知道什么"

最终目标是让 FOMO Killer 从一个信息过滤器，变成一个**主动性的第二大脑**。

不只是告诉你今天发生了什么，而是帮你记住、理解、串联你关心的一切。

---

## 写在最后

做这个项目最大的收获，不是技术上的。

是我学会了一件事：**重要的不是你知道多少，而是你能忽略多少。**

信息焦虑的解药从来不是"看更多"，而是"看对的"。

剩下的，让机器去焦虑就好了。